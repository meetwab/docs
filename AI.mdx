---
title: "AI 伴侣"
---

# 强大，不重要；合适，才重要

AI 的发展速度太快了，从过去的一年发布一次，到半年一次，再到几个月一次。每个模型发布之初都是最强的，用户在不同的模型之间来回切换。从惊艳到麻木，AI 的 S 技术曲线发展到今天，用户的多巴胺已经不太够用了。

我把目前 AI 的使用者分为 3 类：

- 第 1 类占比 10%，人才。其工作具有科研性质，需要 AI 具有强大的推理能力。对于这类人来说，AI 是用来提供创意的。
- 第 2 类占比 60%，普通人。已经有了稳定的工作流程，对于这类人来说，AI 是用来提升效率的。
- 第 3 类占比 30%，普通人。正在入门一个领域，对于这类人来说，AI 是用来当百科全书的。

对于第 2 3 类使用者来说，对于模型的敏感度应该不高，榜单 top20 的模型的输出质量也大同小异。然而，这只是理想情况。人的阅读偏好不同，而且各家模型已经走出了自己的特色：Gemini 超长的上下文容量、Claude 强大的编码能力、ChatGPT 丰富的多模态功能、~~Grok 18 禁的 NSFW~~。

为了寻找与自己最对眼的那一款模型，我在不同的 AI 之间来回切换，查看内容质量。就像宝可梦中，小智独闯世界之前，他需要选择自己最同频的 Pokemon。

# 它变弱了吗？OpenAI—ChatGPT

并没有。

OpenAI 的模型依旧十分强大，但是 ChatGPT 的订阅用户在实际使用时，多数时间无法达到 OpenAI 在发布会上演示的效果。这并不是说模型变糟糕了，一个厨师在高档餐厅时，客人不多、资源充裕、发挥空间大，做出的菜品自然美味。但让其去街边小吃摊迎接 800 个客人时，为了效率做出的东西的质量难免会下降。

也就是说，**AI 模型的核心能力并不会因用户使用频率而自发退化。在** ChatGPT 中，订阅用户通常通过浏览器与后端交互，后台会先采用一些优化策略，然后再才触达模型。

当用户高频提问时，系统可能会启动资源降级。ChatGPT 为防止单个用户在一定时间内消耗过多的服务器资源，会6设定一个阈值；一旦超过阈值，系统可能主动简化推理过程：例如减少模型生成的回答长度，或跳过某些优化步骤以加快响应。这直接导致内容质量下降，用户看到的回答变得简略、缺乏深度。

**那么 API 呢？这种方式为什么很少被降低性能？**

因为 API 请求可以直接触达模型，绕过了网页界面中的会话管理等中间组件。此外，API 调用往往绑定明确的商业协议——付费用户享有服务级别协议（SLA），其中规定了严格的响应时间、错误率和质量标准。

## 真实的使用体验

在 ChatGPT 中，GPT-4o 是我使用频率最高的模型。因为它快，且性能不错。但是我对它有一些非常不满意的地方：

第一点，对指令的遵循度不高：

GPT 默认的输出风格非常零散，像操作手册一样。下面是对同一问题的输出，你觉得哪个回答更好呢？

- **问题的回答风格**

  我在云计算平台上看到比如：GPU 型号、vCPU 核数、内网带宽、CPU 配置、系统盘、数据盘等等这些机器的参数。我有点蒙圈，请帮我详细梳理一下。

第二点，降智。当数个小时内高频使用时会触发降智，它的特点有很多，比如对指令的遵循程度几乎为零、推理模型不思考、无法识别图像等等。当出现降智时，你最好喝杯水休息一下，或者切换到 API 继续疯狂工作。

## ChatGPT 还值得订阅吗？

我无法给出答案 :/

ChatGPT 做了大量的产品化工程的工作，其客户端与网页端都承载了丰富的功能。在日用场景下方便快捷。但是在专业场景下，PLUS 订阅用户唯一能用的模型 GPT-4o 又略显疲态。而且在高频使用后，会出现回答质量降低的情况。

不过，不妨从另一方面 —— API 的收费策略来看一下这个问题。通过 API 使用模型时，OpenAI 按照 token 进行计费，以 GPT-4.1 为例，[其价格为](https://platform.openai.com/docs/pricing)：

计费单位为 1M token

这些数字有点抽象，下面我来具化一下：

token 是模型用来计费的单元，一般情况下模型中 token 和字数的换算比例大致如下：

- 1 个英文字符 ≈ 0.3 个 token。
- 1 个中文字符 ≈ 0.6 个 token。

在实际使用过程中，我们往往会在一个对话窗口内与 AI 进行多轮对话。在正常情况下，每轮对话的费用为 0.014 美元。如果与 AI 交互频率为 50 轮/天，**则每个月的费用为 21.36 美元（折合人民币 154 元）**

以上计算基于「每轮对话的输入为 100 字，输出为 2300字」，实际的费用波动会在 10-20% 左右。

这么看，ChatGPT 还挺值得订阅的不是吗？

# 量大管饱的家伙！Google—Gemini

在 Gemini 之前，很少能找到「便宜、好用、速率限制低」的商业化大模型。

Gemini 的模型主要有两个：Gemini flash 与 Gemini pro。在目前的官网上，flash 与 pro 都是动态思考。它会根据问题的难度来决定思考的深度，或者不进行思考直接输出。不过，当使用 API 进行调用时，[可以控制思考的深度](https://ai.google.dev/gemini-api/docs/thinking#tools)：

我最喜欢使用的是 Gemini 2.5 flash thinking。快、可用次数多、性能高，真的，你还能找到别的可以媲美这个模型的存在吗？

- **问题的回答风格**

  我在云计算平台上看到比如：GPU 型号、vCPU 核数、内网带宽、CPU 配置、系统盘、数据盘等等这些机器的参数。我有点蒙圈，请帮我详细梳理一下。

不过相比于 Gemini，我最常使用的是 notebooklm，我已经写过[一篇文章](https://www.notion.so/NotebookLM-ima-1dd9c7e876a080359d32e966dd7866e2?pvs=21)来赞美它了。尤其是在做调研时，把收集的资料放到知识库中，对于我抛出的任何问题，它都可以把相关资料串联起来，AI 用思维导图带我在无序的资料中寻找主线。

# 另辟蹊径的大模型 xAI—Grok

Grok 的月订阅付费高达 30 美元，性价比不高。就实际体验而言，Grok4 并没有与其他家模型拉开显著的差距。优点是指令遵循的比较好，但目前官网一堆 bug，后台在不断地迭代新功能，用户体验不太好。

值得聊的是，Grok4 的护航数字人都个性鲜明。尤其是 Bad Rudi 这小家伙，总是想着掘我家祖坟…

# Anthropic—Claude

封号狂魔，不予评价。

# 强悍的开源大模型 Qwen3

中国与美国做大模型的思路有点不太一样。

在中国，他们把最强的大模型开源，反而自家商用的大模型中规中矩。在美国，闭源商用的都是最好的大模型，而开源的都是性能不怎么样的。

国内的开源大模型，大部分属于刷榜型的高分选手，其实际体验效果并不好。我最喜欢的是阿里巴巴的 Qwen3 模型，没有 DeepSeek 与 kimi 浮夸的文本风格。就文本处理能力这一块，可以媲美御三家（ChatGPT、Claude、Gemini）。

- 问题的回答风格

# 排行榜，它靠谱吗？

**靠谱，但是仅供参考。**

就像手机的排行榜，iPhone 在充电速率、刷新速率、电池容量等方面被一众国产手机按在地上摩擦，但是就实际体验来说，iPhone 名列前茅。LLM 排行榜的情况也类似，我常看的榜单：

- [**Chatbot Arena (formerly LMSYS)**](https://lmarena.ai/?leaderboard)

  Chatbot Arena 是一个开源的众包人工智能基准测试平台，由加州大学伯克利分校 SkyLab 和 LMArena 的研究人员开发。
- [**LiveBench**](https://livebench.ai/#/)

  LiveBench 通过定期发布新问题，以及基于最近发布的数据集、论文、新闻文章和电影概要的问题，来限制潜在的污染。每个问题都有可验证的、客观的真实答案，使得难题可以被准确且自动地评分，无需使用LLM评委。
- [**Artificial Analysis**](https://artificialanalysis.ai/leaderboards/models)

  独立分析 AI 模型和 API 提供商。推理、知识、数学和编码等 9 项评估，还会评估价格、输出速度、延迟等。
- [**SEAL LLM Leaderboards**](https://scale.com/leaderboard)

  由 Scale 的“安全、评估和校准实验室”（SEAL）开发，使用私有数据集以确保公平和无污染的结果。

# 最后

在经过半个月的高频使用，并且消费了 70 美元后，我确定了使用偏好。我知道大模型最大的优点是，它能给你一个答案；大模型最大的缺点是，它太想给你一个答案了。

对于大部分问题，在与 Qwen 3 与 Gemini 2.0 flash thinking 对比之下，基本可以解决。而一些有难度的事情，也会先与它们进行交流，然后把问题和结果一起交给 O3、Qwen 3 与 Gemini 的思考模型，辅助得到最终的结果。

什么，你说没看到 ChatGPT？

她很好，只是我们不合适。毕竟，人怎么能跟钱过不去呢？